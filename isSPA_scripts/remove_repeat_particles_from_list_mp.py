#!/usr/bin/env python3

import argparse
import numpy as np
import multiprocessing as mp
from remove_repeat_particles_from_one_micrograph import remove_repeat_particles_from_one_micrograph

def main():
    """通过颗粒的坐标和欧拉角距离将重复颗粒排除"""
    inlst, num, center, euler_thres, output, score =  parse_command_line()
    with open(inlst, "r") as g:
        inlst_lines = g.readlines()

    # 整理合并后的文件名顺序
    inlst_lines = sorted(inlst_lines, key=lambda line: line.split('\t')[1].split('/')[-1])
    # 将颗粒信息根据照片分开排序 sort particle information according to micrographs
    particles_list = [[0 for x in range(len(inlst_lines))] for y in range(num)]
    number = [0]*num # 用于统计每张照片中的颗粒数 count the number of particles in each micrograph
    
    name = inlst_lines[0].split('\t')[1] # 照片名称 Micrograph name
    jj = 0 # 用于照片编码
    kk = 0 # 用于统计一张照片内的颗粒数
    for i in inlst_lines:
        if i.split('\t')[1] == name:
            particles_list[jj][kk] = i
            kk += 1
        else:
            number[jj] = kk
            jj += 1
            kk = 0
            name = i.split('\t')[1]
            particles_list[jj][kk] = i
            kk += 1
    number[jj] = kk

    # 对每一张照片进行并行计算
    q = mp.Manager().Queue()
    num_cores = mp.cpu_count() - 4
    with mp.Pool(processes=num_cores) as pool:
        pool.starmap(remove_repeat_particles_from_one_micrograph, [(q, number[k], particles_list[k], center, euler_thres, score) for k in range(jj+1)])
    all_lines_list = []
    while not q.empty():
        all_lines_list.append(q.get())
    with open(output, "w") as oo:
        oo.writelines(all_lines_list)

def parse_command_line():
    #提取输入的各个参数
    #usage = "%prog <Detection file> <Number of windows> <Center threshold> <Euler threshold> <Output>"
    parser = argparse.ArgumentParser(description='Remove duplicated particles')
    parser.add_argument('input', metavar='Input_file', help='The .lst file generated by isSPA from target detection')
    parser.add_argument('num', metavar='N', type=int, help='Number of micrographs')
    parser.add_argument('center', metavar='d', type=float, help='The largest distance (pixel) between duplicated points')
    parser.add_argument('euler', metavar='Angle_threshold', type=float, help='The largest angle between two Euler angles')
    parser.add_argument('output', metavar='Output_file', help='The output file')
    parser.add_argument('score', metavar='Score_threshold', type=float, help='The score threshold used to filter particles')

    args = parser.parse_args()

    inlst = args.input
    num = args.num
    center = args.center
    euler_thres = args.euler
    output = args.output
    score = args.score

    return inlst, num, center, euler_thres, output, score

if __name__== "__main__":
    main()